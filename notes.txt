1. Идея

Основная идея Байесовского анализатора заключается в том что мы находим вероятность принадлежности объекта к
классу C, перемножая вероятности наличия каждого признака исследуемого объекта у оъекта класса C и умножая результат на
вероятность случайного объекта относиться к классу C (частотность" класса C)
Это возможно при принятии "наивного" допущения, что признаки экземпляров независимы друг от друга.
Исследуя объект на принадлежность ко всем возможным классам и затем выбирая класс, вероятность принадлежности к
которому навысшая мы находим наиболее вероятный класс объекта.
Так как просто произведение вероятностей при большом количеств множителей стремится к нулю  удобнее использоваь сумму логарифмов
взятых с отрицательным знаком и искать, соответственно, не наибольшеее, а наименьшее значение.
Наховем эту сумму "расхождение с классом C". Тот класс, расхождение с которым минимально и есть наиболее вероятный класс
к которому относится исследуемый образец.

2. реализация 

В качестве особенностй (признаков) экземпляров класса бкдем брать все слова каждого из экземпляров. 

Для обучения анализатора передаем в функцию обучения набор экземпляров различных классов.
Каждый элемент набора включает в себя ID класса, к которому отностися и набор признаков. Вначале производится подсчет
количества экземпляров каждого из классов и вычисление частотностей классов.
Затем, добавив все встреченные признаки в общий массив и указав, сколько раз каждый из признаков был встречен в каждом из классов,
мы получим обученный анализатор.

Функция анализа получает набор признаков анализируемого текста (члова, входящие в него) и рассчитывает расождение этого набора 
с каждым из классов.
Для этого находится сумма логаифмов с отрицательным знаком от количества этого признака в учебных экземплярах проверяемом классе 
деленного на количество признака во всех учебных экземплярах. Затем прибавляется логарифм с отрицательным знаком от частотности
проеряемого класса. Среди всех сумм находится наименьшая. Класс, для которого она найдена – искомый.

В дополнение к наиболее вероятному классу функция возвращает подробный отчет с суммами для всех известных анализатору классах 
а также с индексом совместимости – отношением количества распознанных слов в исследуемом образце и количеству нераспознанных.

3. мысли на тему

Главная особенность такой анхитектуры анализатора, которую необходимо учитывать при построении учебного корпуса и запросов
заключается в том что произведение вероятностей принадлежности экземпляра к классу уходит в ноль при наличие в экземпляре
слова, принадлежащего к другому классу, но отсутствующего в экземплярах текущего. С одной стороны это логично, однако если
в экземпляре есть по по одному уникальному слову из каждого класса, то он уже не может быть проанализирован. К тому же
если, к примеру, проверяемый экземпляр буде предствалять собой точную копию одного из учебных экземпляров класса A 
с одним словом заменненным на слово, уникальное для класса B, то он уже не  может быть распознан как экземпляр класса A.
Если обобщать, то данный анализатор работает наилучшим образом, если пересечение множетв всех особенностей каждого класса
равно их объединению, а различия между классами заключаются лишь в разности частотностей каждой из особенностей.
Казалось бы, в таком случае можно просто учитывать только пересечение множеств всех особенностей каждого класса для анализа,
однако в таком случае мы теряем возможность корректно проанализироватьэкземпляр, содержащий большое число уникальных для класса
особененостей. Например, исследуемый экземпляр сожержит 80 особенностей, уникалных для класса A и 5 особенностей, общих для
классов A и B, частотность которых в B выше частотности в A. Очевидно, что этот экземпляр принадлежит к классу A, однако
анализатор, использующий только пересеяение множиств отнесет его к классу B. 

Таким образм анализатор, использующий весь массив признаков хорошо распознает "центральные" (содержащие
общие признаки) и "уникальные" (содержащие уникальные признаки только одного класса) экземпляры, а "переферийные" (содержащие
уникальные признаки сразу несколькрих классов) экземпляры распознать не в состоянии.
Использующий же лишь пересечение всех массивов признаков анализатор точно так же хорошо распознает "чентральные" экземпляры, а также
может распознать (хоть и с ошибкой) "переферийные", однаок при распознании "уникальных" экземпляров велика вероятность ошибки.
То есть, сужая набор используемых признаков от объединиения признаков классов к пересечению мы расширяем набор распознаваемых
экземпляров за счет точности распознавания.

Таким образом можно положить, что идеальные обучающие данные это набор классов, пересечение массивов признаков которых
равно его объединиению. Анализатору, обученному таким образом лучше давать экземпляры для анализа с наибольшей 
совместимостью для наиболее точного анализа.
Если же данные представляют из себя набор классов с нулевым пересечением, то анализ вырождается в поиск ключевых слов.
Если "переферия" массива признаков (признаки, не лежащие в пересечении всех или же большего числа классов)
сильно превышает "центр", то велика вероятность невозможности расознавания экземпляра.
Такому анализатору лучше давать на распознание экземпляры с малой (но, естественно, не равной нулю) совместимостью,
чтобы с наибольшей вероятностью избежать ситуации невозможности распознания.

Если совместимость равна нулю, то образец относится к классу с наибольшей частотностью.


Также может показаться, что еще одна существенная проблема – различное клоичество проверяемых
признаков в зависимости от класса. В таком случае классический алгоритм получит меньшую вероятность для класса, с 
которым у образца совпало больше признаков даже если их частотность в этом классе выше, чем в остальных.
Однако эта проблема решается тем, что если в другом классе эти признаки не совпали, то в нем их частотноть
и, соответственно, вероятность возникновения равна нулю и единственным возможным классом остается темущий.

Для случая же, когда образец содержит уникальные члены нескольких классов я использую "централььный" алгоритм,
который учитвыает только признаки, содержащиеся в обеих классах.

4. Возможные улучшения

Возможно в полноценной программе удастся реализовать "запосный" алгоритм, который выполняется если анализ попадает в ситуацию 
невозможности распознания. Самый простой пример этого гипотетического алгоритма – анализ по "центру" в случае если экземпляр содержит
уникальные признаки нескольких классов. (такой я в итоге уже сделал)
Однако очевидно, что чистый анализ по "центру" будет давать чудовищную ошибку, так что нужно что-то посложнее.
С другой стороны если экземпляр содержит уникальные признаки нескольких классов, то, возможно, он и не должен быть распознан
Тогда надо просто более тщательно подбрать данные для обцчения, чтобы свести такие ситуаци к минимому.
Вероятно, такой "запасный" алгоритм надо повесить на отдельный флаг, чтобы пользователь мог сам решить, надо ли ему это.

5. Про тесты

Исходя из моих попыток создать нормальный тест для этого анализатора а также из моих предствлений о том как он должен работать 
я пришел к выводу, что нормальный массив обучающих данных должен быть либо очень продуманный (чтобы получить "центральный"
массив признаков) либо очень большим (с той же целью). Иначе при малом корпусе анализатор либо вырождается в поисковик по ключевым словам
(такой прмер у меня есть) либо просто перестает работать с большими текстами (так как они неизбежно содержат уникалььные слова для обоих
классов) а малых наборов слов в любом случае недостаточно чтобы отнести их к какому-либо классу.
Наиболее интересным будет тест с несколькими гигабайтами текстов различных стилей, так чтобы все более ли менее часто используемые
слова английйского языка там присутствовали, однако помещать все это в оперативку я не особо хочу и лучше проведу такой тест уже
с полноценной программой, которая будет хранить данные в виде файлов.

Те немногие наборы обучающих данных, которые я уже протестировал (записаны в приложеном файле "tests") дают достаточно
низкою точность, порядка 60% (в первую очередь, как мне кажется, из-за недостаточного числа обучающих экземпляров)

